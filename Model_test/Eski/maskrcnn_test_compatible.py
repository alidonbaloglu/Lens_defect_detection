import os
import pandas as pd
import torch
import torchvision
import numpy as np
import cv2
from torchvision.transforms import functional as F
from torchvision.models.detection.backbone_utils import resnet_fpn_backbone
from torchvision.models.detection import MaskRCNN
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchvision.models.detection.roi_heads import RoIHeads
from PIL import Image
import torch.nn.functional as F_torch

# --- AYARLAR ---
MASKRCNN_MODEL_PATH = "C:/Users/ali.donbaloglu/Desktop/Lens/results/best_params_run/maskrcnn_resnet101_best_v1.pt"
MASKRCNN_BACKBONE = "resnet101"
DATASET_DIR = 'test_dataset/test-yeni_kabin'
NUM_CLASSES = 7  # EÄŸitim kodunda olduÄŸu gibi 7 sÄ±nÄ±f
CLASS_NAMES = [
    "background",
    "cizik",
    "enjeksiyon_noktasi",
    "kirik",
    "siyah_nokta",
    "siyahlk",
    "yabanci"
]
OUTPUT_EXCEL_PATH = 'maskrcnn_yenikabin_test_sonuclari.xlsx'

CONFIDENCE_THRESHOLD = 0.5
IOU_THRESHOLD = 0.4


# --- YARDIMCI SINIFLAR (EÄŸitim kodundan alÄ±ndÄ±) ---
class MultiModalPreprocessor:
    """GÃ¶rÃ¼ntÃ¼den RGB, Kenar (Edge) ve Gradyan kanallarÄ±nÄ± Ã§Ä±karÄ±r."""
    def __call__(self, image_np: np.ndarray):
        gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
        
        # Kenar tespiti (Canny)
        edges = cv2.Canny(gray, 60, 150)
        
        # Gradyan tespiti (Sobel)
        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        gradient = np.sqrt(sobelx**2 + sobely**2)
        # Normalizasyon
        if gradient.max() > 0:
            gradient = (gradient / gradient.max() * 255).astype(np.uint8)
        
        return {
            'image': image_np,
            'edge': np.expand_dims(edges, axis=-1),
            'gradient': np.expand_dims(gradient, axis=-1)
        }


class RefinedMaskRCNNPredictor(torch.nn.Module):
    """Kontur (sÄ±nÄ±r) bilgisiyle zenginleÅŸtirilmiÅŸ maske tahmincisi."""
    def __init__(self, in_channels, dim_reduced, num_classes):
        super().__init__()
        self.conv5_mask = torch.nn.ConvTranspose2d(in_channels, dim_reduced, 2, 2, 0)
        self.relu = torch.nn.ReLU(inplace=True)
        self.mask_fcn_logits = torch.nn.Conv2d(dim_reduced, num_classes, 1, 1, 0)
        
        # Kontur iyileÅŸtirme katmanlarÄ±
        self.contour_conv1 = torch.nn.Conv2d(dim_reduced, 128, 3, padding=1)
        self.contour_conv2 = torch.nn.Conv2d(128, 64, 3, padding=1)
        self.contour_conv3 = torch.nn.Conv2d(64, num_classes, 1)
    
    def forward(self, x):
        x = self.conv5_mask(x)
        x = self.relu(x)
        
        mask_logits = self.mask_fcn_logits(x)
        
        # Kontur tahmini ve ana maskeye eklenmesi
        contour = self.relu(self.contour_conv1(x))
        contour = self.relu(self.contour_conv2(contour))
        contour_logits = self.contour_conv3(contour)
        
        # Ana maske ve kontur bilgisini birleÅŸtir
        return mask_logits + 0.3 * contour_logits


class BoundaryAwareRoIHeads(RoIHeads):
    """RoIHeads sÄ±nÄ±fÄ± - test iÃ§in temel kullanÄ±m."""
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)


# --- YARDIMCI FONKSÄ°YONLAR ---
def get_ground_truth(label_path):
    """Birden fazla ground truth etiketi dÃ¶ndÃ¼rÃ¼r: [(class_id, gt_box), ...]"""
    gt_list = []
    try:
        with open(label_path, 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                parts = [float(p) for p in line.split()]
                class_id = int(parts[0])
                points = parts[1:]
                x_coords = points[0::2]
                y_coords = points[1::2]
                x_min, y_min = min(x_coords), min(y_coords)
                x_max, y_max = max(x_coords), max(y_coords)
                gt_box = [(x_min + x_max) / 2, (y_min + y_max) / 2,
                          x_max - x_min, y_max - y_min]
                gt_list.append((class_id, gt_box))
        return gt_list
    except (FileNotFoundError, ValueError):
        return []


def calculate_iou(boxA, boxB):
    """Ä°ki kutu arasÄ±ndaki IoU oranÄ±nÄ± hesaplar. [x_center, y_center, width, height] formatÄ±nda olmalÄ±."""
    def to_corners(box):
        x_center, y_center, w, h = box
        return [x_center - w / 2, y_center - h / 2,
                x_center + w / 2, y_center + h / 2]

    boxA_corners, boxB_corners = to_corners(boxA), to_corners(boxB)
    xA = max(boxA_corners[0], boxB_corners[0])
    yA = max(boxA_corners[1], boxB_corners[1])
    xB = min(boxA_corners[2], boxB_corners[2])
    yB = min(boxA_corners[3], boxB_corners[3])

    interArea = max(0, xB - xA) * max(0, yB - yA)
    boxAArea = boxA[2] * boxA[3]
    boxBArea = boxB[2] * boxB[3]
    if boxAArea + boxBArea - interArea == 0:
        return 0
    return interArea / float(boxAArea + boxBArea - interArea)


def create_enhanced_maskrcnn(num_classes):
    """EÄŸitim kodundan aynÄ± ÅŸekilde model oluÅŸturur."""
    backbone = resnet_fpn_backbone(MASKRCNN_BACKBONE, weights=True)
    
    # Ä°lk conv katmanÄ±nÄ± 5 kanallÄ± giriÅŸe uyarla
    original_conv1 = backbone.body.conv1
    new_conv1 = torch.nn.Conv2d(
        5, original_conv1.out_channels,
        kernel_size=original_conv1.kernel_size,
        stride=original_conv1.stride,
        padding=original_conv1.padding,
        bias=(original_conv1.bias is not None)
    )
    with torch.no_grad():
        # RGB aÄŸÄ±rlÄ±klarÄ±nÄ± kopyala
        new_conv1.weight[:, :3, :, :] = original_conv1.weight
        # Extra kanallarÄ± RGB aÄŸÄ±rlÄ±klarÄ±nÄ±n ortalamasÄ± olarak baÅŸlat
        new_conv1.weight[:, 3:, :, :] = original_conv1.weight.mean(dim=1, keepdim=True)

    backbone.body.conv1 = new_conv1

    # MaskRCNN modelini oluÅŸtur
    model = MaskRCNN(backbone, num_classes=num_classes)

    # Kutu tahmincisini ayarla
    in_features_box = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features_box, num_classes)

    # Maske tahmincisini deÄŸiÅŸtir
    try:
        in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels
        model.roi_heads.mask_predictor = RefinedMaskRCNNPredictor(in_features_mask, 256, num_classes)
    except Exception:
        pass

    # Modelin transform'Ä±nÄ± 5 kanala uyarla
    try:
        from torchvision.models.detection.transform import GeneralizedRCNNTransform
        img_mean = [0.485, 0.456, 0.406, 0.5, 0.5]
        img_std = [0.229, 0.224, 0.225, 0.5, 0.5]
        model.transform = GeneralizedRCNNTransform(800, 1333, image_mean=img_mean, image_std=img_std)
    except Exception:
        pass

    return model


def load_maskrcnn_model(weights_path, num_classes, device):
    """Modeli aÄŸÄ±rlÄ±klarla birlikte yÃ¼kler."""
    model = create_enhanced_maskrcnn(num_classes)
    try:
        checkpoint = torch.load(weights_path, map_location=device)
        # Checkpoint'in state_dict'ini Ã§Ä±kar
        state_dict = checkpoint.get('state_dict', checkpoint)
        
        # strict=False kullanarak uyumsuz aÄŸÄ±rlÄ±klarÄ± yÃ¼kle
        model.load_state_dict(state_dict, strict=False)
        model.to(device).eval()
        print(f"âœ… Model baÅŸarÄ±yla yÃ¼klendi: {weights_path}")
        return model
    except Exception as e:
        print(f"HATA: Mask R-CNN modeli yÃ¼klenemedi. Hata: {e}")
        raise


def preprocess_image(image_path, device):
    """GÃ¶rÃ¼ntÃ¼yÃ¼ 5 kanallÄ± tensÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r."""
    img = Image.open(image_path).convert("RGB")
    img_np = np.array(img)
    
    # Multi-modal preprocessing
    preprocessor = MultiModalPreprocessor()
    modalities = preprocessor(img_np)
    
    # KanallarÄ± birleÅŸtir: RGB (3) + Edge (1) + Gradient (1) = 5 kanal
    rgb_tensor = torch.from_numpy(modalities['image']).permute(2, 0, 1).float() / 255.0
    edge_tensor = torch.from_numpy(modalities['edge']).permute(2, 0, 1).float() / 255.0
    gradient_tensor = torch.from_numpy(modalities['gradient']).permute(2, 0, 1).float() / 255.0
    
    # 5 kanallÄ± tensor oluÅŸtur
    multi_modal_tensor = torch.cat([rgb_tensor, edge_tensor, gradient_tensor], dim=0)
    
    return multi_modal_tensor.to(device), img


# --- ANA SCRIPT ---
@torch.no_grad()
def main_maskrcnn():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ”§ KullanÄ±lan cihaz: {device}")
    
    # Modeli yÃ¼kle
    model = load_maskrcnn_model(MASKRCNN_MODEL_PATH, NUM_CLASSES, device)

    images_dir = os.path.join(DATASET_DIR, 'images')
    labels_dir = os.path.join(DATASET_DIR, 'labels')
    
    if not os.path.exists(images_dir):
        print(f"âŒ Hata: {images_dir} dizini bulunamadÄ±!")
        return
    
    image_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    print(f"ğŸ“· {len(image_files)} gÃ¶rÃ¼ntÃ¼ bulundu.")

    results_list = []

    for idx, image_name in enumerate(image_files, 1):
        image_path = os.path.join(images_dir, image_name)
        label_path = os.path.join(labels_dir, os.path.splitext(image_name)[0] + '.txt')

        gt_items = get_ground_truth(label_path)

        if not gt_items:
            results_list.append({
                'FotoÄŸraf AdÄ±': image_name,
                'GerÃ§ek Etiket': 'Etiket DosyasÄ± Yok/Bozuk',
                'Tahmin Edilen Etiket': 'N/A',
                'IoU': 0,
                'SonuÃ§': 'Belirsiz'
            })
            print(f"[{idx}/{len(image_files)}] {image_name} - Etiket yok")
            continue

        # GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kle ve iÅŸle
        img_tensor, original_img = preprocess_image(image_path, device)
        outputs = model([img_tensor])

        # Mask R-CNN tahminlerini filtrele
        scores = outputs[0]['scores']
        keep_indices = scores > CONFIDENCE_THRESHOLD

        if keep_indices.any():
            boxes = outputs[0]['boxes'][keep_indices]
            labels = outputs[0]['labels'][keep_indices]
        else:
            boxes, labels = [], []

        img_w, img_h = original_img.size

        # Her ground truth objesi iÃ§in kontrol yap
        for gt_class_id_yolo, gt_box in gt_items:
            gt_class_id_mrcnn = gt_class_id_yolo + 1  # COCO formatÄ±nda background sÄ±nÄ±f vardÄ±r
            
            # SÄ±nÄ±r kontrolÃ¼
            if gt_class_id_mrcnn >= len(CLASS_NAMES):
                gt_class_id_mrcnn = len(CLASS_NAMES) - 1
            
            gt_label_str = CLASS_NAMES[gt_class_id_mrcnn] if gt_class_id_mrcnn < len(CLASS_NAMES) else "Bilinmeyen"

            best_iou = 0
            best_match_label = "Tespit Edilemedi"
            found_correct = False

            for box, label in zip(boxes, labels):
                x1, y1, x2, y2 = box.tolist()
                pred_box = [((x1 + x2) / 2) / img_w, ((y1 + y2) / 2) / img_h,
                            (x2 - x1) / img_w, (y2 - y1) / img_h]
                pred_class_id = label.item()

                iou = calculate_iou(gt_box, pred_box)

                if pred_class_id == gt_class_id_mrcnn and iou > IOU_THRESHOLD:
                    found_correct = True
                    best_iou = iou
                    best_match_label = CLASS_NAMES[pred_class_id] if pred_class_id < len(CLASS_NAMES) else "Bilinmeyen"
                    break

                if iou > best_iou:
                    best_iou = iou
                    best_match_label = CLASS_NAMES[pred_class_id] if pred_class_id < len(CLASS_NAMES) else "Bilinmeyen"

            sonuc = "DoÄŸru" if found_correct else ("YanlÄ±ÅŸ" if best_match_label != "Tespit Edilemedi" else "Tespit Edilemedi")

            results_list.append({
                'FotoÄŸraf AdÄ±': image_name,
                'GerÃ§ek Etiket': gt_label_str,
                'Tahmin Edilen Etiket': best_match_label,
                'IoU': f"{best_iou:.2f}",
                'SonuÃ§': sonuc
            })

            print(f"[{idx}/{len(image_files)}] {image_name} | Etiket='{gt_label_str}', Tahmin='{best_match_label}', IoU={best_iou:.2f} -> {sonuc}")

    # SonuÃ§larÄ± Excel'e kaydet
    df = pd.DataFrame(results_list)
    df.to_excel(OUTPUT_EXCEL_PATH, index=False)
    
    # Ä°statistikleri yazdÄ±r
    print(f"\n{'='*60}")
    print(f"âœ… Ä°ÅŸlem tamamlandÄ±! SonuÃ§lar '{OUTPUT_EXCEL_PATH}' dosyasÄ±na kaydedildi.")
    print(f"{'='*60}")
    
    if results_list:
        correct_count = sum(1 for r in results_list if r['SonuÃ§'] == 'DoÄŸru')
        wrong_count = sum(1 for r in results_list if r['SonuÃ§'] == 'YanlÄ±ÅŸ')
        undetected_count = sum(1 for r in results_list if r['SonuÃ§'] == 'Tespit Edilemedi')
        
        print(f"ğŸ“Š Ä°statistikler:")
        print(f"   âœ“ DoÄŸru Tahmin: {correct_count}")
        print(f"   âœ— YanlÄ±ÅŸ Tahmin: {wrong_count}")
        print(f"   âš  Tespit Edilemedi: {undetected_count}")
        print(f"   ğŸ“ˆ BaÅŸarÄ± OranÄ±: {100*correct_count/len(results_list):.2f}%")


if __name__ == '__main__':
    main_maskrcnn()
